{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clutch/anaconda3/envs/insight/lib/python3.7/site-packages/sqlalchemy/sql/functions.py:68: SAWarning: The GenericFunction 'array_agg' is already registered and is going to be overriden.\n",
      "  \"is going to be overriden.\".format(identifier))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import json\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import create_database, database_exists, drop_database\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages to perform Text Summarization on Youtube Video Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "# build a list of stopwords\n",
    "stopwords = list(STOP_WORDS)\n",
    "# load spacy english language\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to summarize comments for \n",
    "# each video with >=N number of comments\n",
    "def text_summarizer(document):\n",
    "    \"\"\"\n",
    "    input: concatenated comments >= 10 min read time\n",
    "          which is approximately 2000 characters\n",
    "    return: a summarized version of the comments of\n",
    "           about 2-4 minutes read time (400-800 characters)\n",
    "    \"\"\"\n",
    "    # raw_text = document\n",
    "    doc = nlp(document)\n",
    "    # build word frequency\n",
    "    # word.text is tokenization in spacy\n",
    "    word_frequencies = {}  \n",
    "    for word in doc:  \n",
    "        if word.text not in stopwords:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    # sentence tokens\n",
    "    sentence_list = [ sentence for sentence in doc.sents ]\n",
    "\n",
    "    # calculate sentence score and ranking\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if len(sent.text.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "    # find N largest\n",
    "    summary_sentences = nlargest(6, sentence_scores, key=sentence_scores.get)\n",
    "    \n",
    "    summarized_sentences_cleaned = []\n",
    "    for ss in summary_sentences:\n",
    "        if ss.text.find(', ')==0:\n",
    "            idx = ss.text.find(', ')\n",
    "            new_ss = ss[idx+1:].text.capitalize()\n",
    "        else:\n",
    "            new_ss = ss.text.capitalize()\n",
    "            new_ss = ' '.join(new_ss.split())\n",
    "        summarized_sentences_cleaned.append(new_ss)\n",
    "    \n",
    "#     final_sentences = []\n",
    "#     for w in summarized_sentences_cleaned:\n",
    "#         for i, a in enumerate(w.text):\n",
    "#             if a.isalpha():\n",
    "#                 break\n",
    "#         final_sentences.append(w.text[i:].capitalize())\n",
    "    \n",
    "    summary = ' '.join(summarized_sentences_cleaned)\n",
    "    summary = summary.replace(u'\\xa0', u'')\n",
    "#     print(\"Original Document\\n\")\n",
    "#     print(document)\n",
    "#     print(\"Total Length:\",len(document))\n",
    "#     print('\\n\\nSummarized Document\\n')\n",
    "#     print(summary)\n",
    "#     print(\"Total Length:\",len(summary))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original csv file of video titles, subtitles, comments, labels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_csv_filename = 'data/csv_files/original_data.csv'\n",
    "data_df = pd.read_csv(from_csv_filename, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.sort_values('txt_len', ascending=False).head()\n",
    "cols = list(data_df.columns)\n",
    "cols.append('summary')\n",
    "#cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[(data_df['txt_len']>=2000) & (data_df['txt_len']<100000)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_list = list(data_df.video_id)\n",
    "len(video_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>text</th>\n",
       "      <th>txt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09Q4JQ3p8yg</td>\n",
       "      <td>How to remove popcorn stipple ceiling</td>\n",
       "      <td>hi Shannon here from health improvements and t...</td>\n",
       "      <td>drywall_repair</td>\n",
       "      <td>asmr **, I love you, Im here from Instagram lm...</td>\n",
       "      <td>90480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0Aip_xxpia4</td>\n",
       "      <td>How to install carpet tiles</td>\n",
       "      <td>were going to replace this tired old wall-to-w...</td>\n",
       "      <td>carpet_flooring</td>\n",
       "      <td>Interface do a product called tactiles which a...</td>\n",
       "      <td>2183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0COOF3BwgKI</td>\n",
       "      <td>Fix small nail holes in walls fast and make th...</td>\n",
       "      <td>so you like to hang pictures on your wall if y...</td>\n",
       "      <td>drywall_repair</td>\n",
       "      <td>Glad I could help then.  Be sure and subscribe...</td>\n",
       "      <td>8009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0J8q_Lsh4fU</td>\n",
       "      <td>Hog wire deck rail installation</td>\n",
       "      <td>hi im paul from Elkins diy.com today Im going ...</td>\n",
       "      <td>build_deck</td>\n",
       "      <td>Thanks Naegling, off topic but where are u get...</td>\n",
       "      <td>8102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0RuwaSU71rY</td>\n",
       "      <td>Replacing a section of drywall after a pipe leak</td>\n",
       "      <td>hi Im Mike Thompson last night was a bit of an...</td>\n",
       "      <td>drywall_repair</td>\n",
       "      <td>Great Job , Mike Thompson, good instructional ...</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  09Q4JQ3p8yg              How to remove popcorn stipple ceiling   \n",
       "1  0Aip_xxpia4                        How to install carpet tiles   \n",
       "2  0COOF3BwgKI  Fix small nail holes in walls fast and make th...   \n",
       "3  0J8q_Lsh4fU                    Hog wire deck rail installation   \n",
       "4  0RuwaSU71rY   Replacing a section of drywall after a pipe leak   \n",
       "\n",
       "                                           subtitles primary_category  \\\n",
       "0  hi Shannon here from health improvements and t...   drywall_repair   \n",
       "1  were going to replace this tired old wall-to-w...  carpet_flooring   \n",
       "2  so you like to hang pictures on your wall if y...   drywall_repair   \n",
       "3  hi im paul from Elkins diy.com today Im going ...       build_deck   \n",
       "4  hi Im Mike Thompson last night was a bit of an...   drywall_repair   \n",
       "\n",
       "                                                text  txt_len  \n",
       "0  asmr **, I love you, Im here from Instagram lm...    90480  \n",
       "1  Interface do a product called tactiles which a...     2183  \n",
       "2  Glad I could help then.  Be sure and subscribe...     8009  \n",
       "3  Thanks Naegling, off topic but where are u get...     8102  \n",
       "4  Great Job , Mike Thompson, good instructional ...     4012  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for i, vid in enumerate(video_id_list):\n",
    "    document = str(data_df.iloc[i].text)\n",
    "    summary = text_summarizer(document)\n",
    "    new_df.loc[i] = [str(data_df.loc[i].video_id), str(data_df.loc[i].title), \n",
    "                     str(data_df.loc[i].subtitles), str(data_df.loc[i].primary_category), \n",
    "                     str(data_df.loc[i].text), str(data_df.loc[i].txt_len), str(summary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       656\n",
       "1       398\n",
       "2       658\n",
       "3       522\n",
       "4       623\n",
       "5       593\n",
       "6       596\n",
       "7       464\n",
       "8       561\n",
       "9       555\n",
       "10      495\n",
       "11      688\n",
       "12      505\n",
       "13      719\n",
       "14      745\n",
       "15      668\n",
       "16      584\n",
       "17      533\n",
       "18      343\n",
       "19      636\n",
       "20      601\n",
       "21      559\n",
       "22      476\n",
       "23      692\n",
       "24      631\n",
       "25      630\n",
       "26      627\n",
       "27      895\n",
       "28      624\n",
       "29      634\n",
       "       ... \n",
       "1007    589\n",
       "1008    650\n",
       "1009    661\n",
       "1010    443\n",
       "1011    674\n",
       "1012    559\n",
       "1013    558\n",
       "1014    558\n",
       "1015    555\n",
       "1016    680\n",
       "1017    736\n",
       "1018    626\n",
       "1019    374\n",
       "1020    506\n",
       "1021    579\n",
       "1022    692\n",
       "1023    652\n",
       "1024    579\n",
       "1025    677\n",
       "1026    423\n",
       "1027    552\n",
       "1028    755\n",
       "1029    523\n",
       "1030    670\n",
       "1031    641\n",
       "1032    729\n",
       "1033    757\n",
       "1034    509\n",
       "1035    844\n",
       "1036    566\n",
       "Name: summary, Length: 1037, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['summary'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['summary_len'] = new_df['summary'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       656\n",
       "1       398\n",
       "2       658\n",
       "3       522\n",
       "4       623\n",
       "5       593\n",
       "6       596\n",
       "7       464\n",
       "8       561\n",
       "9       555\n",
       "10      495\n",
       "11      688\n",
       "12      505\n",
       "13      719\n",
       "14      745\n",
       "15      668\n",
       "16      584\n",
       "17      533\n",
       "18      343\n",
       "19      636\n",
       "20      601\n",
       "21      559\n",
       "22      476\n",
       "23      692\n",
       "24      631\n",
       "25      630\n",
       "26      627\n",
       "27      895\n",
       "28      624\n",
       "29      634\n",
       "       ... \n",
       "1007    589\n",
       "1008    650\n",
       "1009    661\n",
       "1010    443\n",
       "1011    674\n",
       "1012    559\n",
       "1013    558\n",
       "1014    558\n",
       "1015    555\n",
       "1016    680\n",
       "1017    736\n",
       "1018    626\n",
       "1019    374\n",
       "1020    506\n",
       "1021    579\n",
       "1022    692\n",
       "1023    652\n",
       "1024    579\n",
       "1025    677\n",
       "1026    423\n",
       "1027    552\n",
       "1028    755\n",
       "1029    523\n",
       "1030    670\n",
       "1031    641\n",
       "1032    729\n",
       "1033    757\n",
       "1034    509\n",
       "1035    844\n",
       "1036    566\n",
       "Name: summary_len, Length: 1037, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.summary_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.summary_len = new_df.summary_len.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.txt_len = new_df.txt_len.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['prcnt_reduce'] = ((new_df.txt_len - new_df.summary_len) / new_df.txt_len) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.91334399199954"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.prcnt_reduce.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd11fb41d68>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['prcnt_reduce'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv_filename = 'data/csv_files/summarized_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(to_csv_filename, sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
